{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2122ce-771c-4505-bbb3-0879a523e357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0270dc-f8af-46b6-b5a3-8c04a730b53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path where all quarter folders are stored\n",
    "DATA_PATH = r\"D:\\Resume\\KPMG\\Automated Financial Risk Scoring Platform (Machine Learning + LLM)\"\n",
    "\n",
    "# Required financial tags\n",
    "REQUIRED_TAGS = [\n",
    "    # Income Statement\n",
    "    \"Revenues\",\n",
    "    \"NetIncomeLoss\",\n",
    "    \"OperatingIncomeLoss\",\n",
    "    \"InterestExpense\",\n",
    "    \n",
    "    # Balance Sheet\n",
    "    \"Assets\",\n",
    "    \"Liabilities\",\n",
    "    \"StockholdersEquity\",\n",
    "    \"AssetsCurrent\",\n",
    "    \"LiabilitiesCurrent\",\n",
    "    \"CashAndCashEquivalentsAtCarryingValue\",\n",
    "    \"LongTermDebtNoncurrent\",\n",
    "    \n",
    "    # Cash Flow\n",
    "    \"NetCashProvidedByUsedInOperatingActivities\",\n",
    "    \"PaymentsToAcquirePropertyPlantAndEquipment\"\n",
    "]\n",
    "\n",
    "def load_all_quarters():\n",
    "    all_data = []\n",
    "    \n",
    "    for quarter_folder in os.listdir(DATA_PATH):\n",
    "        quarter_path = os.path.join(DATA_PATH, quarter_folder, \"num.txt\")\n",
    "        \n",
    "        if os.path.exists(quarter_path):\n",
    "            print(f\"Loading {quarter_folder}...\")\n",
    "            \n",
    "            df = pd.read_csv(quarter_path, sep=\"\\t\", low_memory=False)\n",
    "            \n",
    "            # Filter required tags\n",
    "            df = df[df[\"tag\"].isin(REQUIRED_TAGS)]\n",
    "            \n",
    "            # Keep only USD values\n",
    "            df = df[df[\"uom\"] == \"USD\"]\n",
    "            \n",
    "            # Keep annual and balance sheet values\n",
    "            df = df[df[\"qtrs\"].isin([0, 4])]\n",
    "            \n",
    "            # Keep required columns\n",
    "            df = df[[\"adsh\", \"tag\", \"ddate\", \"qtrs\", \"value\"]]\n",
    "            \n",
    "            all_data.append(df)\n",
    "    \n",
    "    final_df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = load_all_quarters()\n",
    "    print(df.head())\n",
    "    print(\"Total rows:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceec545c-3d94-4cbd-a388-f761e1b575f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "REQUIRED_TAGS = [\n",
    "    \"Revenues\",\n",
    "    \"NetIncomeLoss\",\n",
    "    \"OperatingIncomeLoss\",\n",
    "    \"InterestExpense\",\n",
    "    \"Assets\",\n",
    "    \"Liabilities\",\n",
    "    \"StockholdersEquity\",\n",
    "    \"AssetsCurrent\",\n",
    "    \"LiabilitiesCurrent\",\n",
    "    \"CashAndCashEquivalentsAtCarryingValue\",\n",
    "    \"LongTermDebtNoncurrent\",\n",
    "    \"NetCashProvidedByUsedInOperatingActivities\",\n",
    "    \"PaymentsToAcquirePropertyPlantAndEquipment\"\n",
    "]\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for quarter_folder in os.listdir(DATA_PATH):\n",
    "    quarter_path = os.path.join(DATA_PATH, quarter_folder, \"num.txt\")\n",
    "    \n",
    "    if os.path.exists(quarter_path):\n",
    "        print(f\"Loading {quarter_folder}...\")\n",
    "        \n",
    "        df = pd.read_csv(quarter_path, sep=\"\\t\", low_memory=False)\n",
    "        df = df[df[\"tag\"].isin(REQUIRED_TAGS)]\n",
    "        df = df[df[\"uom\"] == \"USD\"]\n",
    "        df = df[df[\"qtrs\"].isin([0, 4])]\n",
    "        df = df[[\"adsh\", \"tag\", \"ddate\", \"qtrs\", \"value\"]]\n",
    "        \n",
    "        all_data.append(df)\n",
    "\n",
    "final_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "print(\"Final shape:\", final_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99397bb-a2cc-4bee-86e3-560c21b44c57",
   "metadata": {},
   "source": [
    "### Pivot to Structured Company-Level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005763e2-4bb6-4019-88c8-8671576a6faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_df = final_df.pivot_table(\n",
    "    index=[\"adsh\", \"ddate\"],\n",
    "    columns=\"tag\",\n",
    "    values=\"value\",\n",
    "    aggfunc=\"first\"\n",
    ").reset_index()\n",
    "\n",
    "print(\"Structured shape:\", structured_df.shape)\n",
    "structured_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cb79a2-e6f7-48f9-a6d3-8338e4ba0a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f823cfae-ca27-427c-bf77-d97f06d626ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total rows:\", structured_df.shape[0])\n",
    "\n",
    "step1 = structured_df.dropna(subset=[\"Assets\", \"Liabilities\"])\n",
    "print(\"After keeping Assets & Liabilities:\", step1.shape[0])\n",
    "\n",
    "step2 = step1.dropna(subset=[\"Revenues\"])\n",
    "print(\"After keeping Revenues:\", step2.shape[0])\n",
    "\n",
    "step3 = step2.dropna(subset=[\"NetIncomeLoss\"])\n",
    "print(\"After keeping NetIncomeLoss:\", step3.shape[0])\n",
    "\n",
    "step4 = step3.dropna(subset=[\"StockholdersEquity\"])\n",
    "print(\"After keeping Equity:\", step4.shape[0])\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b164f7a-15aa-4019-86b1-318b59ef0e8c",
   "metadata": {},
   "source": [
    "Excellent. Now we see the reality clearly.\n",
    "From 219,962 filings ‚Üí 7,970 usable financial statements.\n",
    "That drop is expected.\n",
    "\n",
    "SEC data includes:\n",
    "Funds\n",
    "Shell entities\n",
    "Special filings\n",
    "Non-operating firms\n",
    "Partial disclosures\n",
    "Only ~8k have full core financials.\n",
    "That is still perfectly fine for ML.\n",
    "\n",
    "üéØ Decision\n",
    "We will use these 7,970 complete filings.\n",
    "Quality > quantity.\n",
    "This is real company-level annual financial data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b6748b-f4ac-4aa4-81f6-b5051254ce84",
   "metadata": {},
   "source": [
    "### Create Clean Modeling Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473b80b5-8ea4-4407-98b0-1c727d5408e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = structured_df.dropna(subset=[\n",
    "    \"Assets\",\n",
    "    \"Liabilities\",\n",
    "    \"Revenues\",\n",
    "    \"NetIncomeLoss\",\n",
    "    \"StockholdersEquity\"\n",
    "])\n",
    "\n",
    "print(\"Final clean dataset shape:\", clean_df.shape)\n",
    "\n",
    "clean_df.head()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "548f74cd-115b-4ad0-9ee8-0c1f979b9e3e",
   "metadata": {},
   "source": [
    "üß† Important\n",
    "\n",
    "Now we have:\n",
    "~8,000 real company annual financial statements\n",
    "Proper balance sheet + income data\n",
    "Ready for feature engineering\n",
    "This is where the real finance intelligence begins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b0c5dc-2917-467a-9443-6da57c1cdc0e",
   "metadata": {},
   "source": [
    "### Financial Ratio Engineering"
   ]
  },
  {
   "cell_type": "raw",
   "id": "43d77a96-9b2f-43d0-84c3-2c7b262e6396",
   "metadata": {},
   "source": [
    "We now create domain-driven risk features.\n",
    "These are what banks actually use.\n",
    "\n",
    "üßÆ 1Ô∏è‚É£ Liquidity Ratios\n",
    "Measure short-term solvency.\n",
    "Current Ratio = AssetsCurrent / LiabilitiesCurrent\n",
    "Cash Ratio = Cash / LiabilitiesCurrent\n",
    "Higher = safer.\n",
    "\n",
    "üßÆ 2Ô∏è‚É£ Leverage Ratios\n",
    "Measure debt burden.\n",
    "Debt to Equity = Liabilities / StockholdersEquity\n",
    "Debt to Assets = Liabilities / Assets\n",
    "Higher = riskier.\n",
    "\n",
    "üßÆ 3Ô∏è‚É£ Profitability Ratios\n",
    "Measure earnings strength.\n",
    "Net Profit Margin = NetIncome / Revenues\n",
    "Return on Assets (ROA) = NetIncome / Assets\n",
    "Return on Equity (ROE) = NetIncome / Equity\n",
    "Lower or negative = risk.\n",
    "\n",
    "üßÆ 4Ô∏è‚É£ Cash Flow Strength\n",
    "Operating Cash Flow Ratio = OCF / Liabilities\n",
    "Free Cash Flow = OCF - CapEx\n",
    "Positive FCF = good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27bd069-57c5-482e-b698-b08ac9718bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Copy clean dataset\n",
    "feature_df = clean_df.copy()\n",
    "\n",
    "# ---------------------------\n",
    "# Liquidity Ratios\n",
    "# ---------------------------\n",
    "feature_df[\"current_ratio\"] = feature_df[\"AssetsCurrent\"] / feature_df[\"LiabilitiesCurrent\"]\n",
    "feature_df[\"cash_ratio\"] = feature_df[\"CashAndCashEquivalentsAtCarryingValue\"] / feature_df[\"LiabilitiesCurrent\"]\n",
    "\n",
    "# ---------------------------\n",
    "# Leverage Ratios\n",
    "# ---------------------------\n",
    "feature_df[\"debt_to_equity\"] = feature_df[\"Liabilities\"] / feature_df[\"StockholdersEquity\"]\n",
    "feature_df[\"debt_to_assets\"] = feature_df[\"Liabilities\"] / feature_df[\"Assets\"]\n",
    "\n",
    "# ---------------------------\n",
    "# Profitability Ratios\n",
    "# ---------------------------\n",
    "feature_df[\"net_profit_margin\"] = feature_df[\"NetIncomeLoss\"] / feature_df[\"Revenues\"]\n",
    "feature_df[\"return_on_assets\"] = feature_df[\"NetIncomeLoss\"] / feature_df[\"Assets\"]\n",
    "feature_df[\"return_on_equity\"] = feature_df[\"NetIncomeLoss\"] / feature_df[\"StockholdersEquity\"]\n",
    "\n",
    "# ---------------------------\n",
    "# Cash Flow Metrics\n",
    "# ---------------------------\n",
    "feature_df[\"free_cash_flow\"] = (\n",
    "    feature_df[\"NetCashProvidedByUsedInOperatingActivities\"] -\n",
    "    feature_df[\"PaymentsToAcquirePropertyPlantAndEquipment\"]\n",
    ")\n",
    "\n",
    "feature_df[\"operating_cf_ratio\"] = (\n",
    "    feature_df[\"NetCashProvidedByUsedInOperatingActivities\"] /\n",
    "    feature_df[\"Liabilities\"]\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# Replace infinite values\n",
    "# ---------------------------\n",
    "feature_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "feature_df.head()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "84be33cf-0075-47f5-80be-87dab792ecca",
   "metadata": {},
   "source": [
    "when you say higher = safer, what is the threshold value\n",
    "\n",
    "There is no universal fixed threshold, but finance has practical benchmark ranges.\n",
    "Here are realistic industry guidelines:\n",
    "\n",
    "üßÆ 1Ô∏è‚É£ Current Ratio\n",
    "(Current Assets / Current Liabilities)\n",
    "Interpretation:\n",
    "< 1.0 ‚Üí üö® High short-term risk (cannot cover obligations)\n",
    "1.0 ‚Äì 1.5 ‚Üí ‚ö† Moderate risk\n",
    "1.5 ‚Äì 3.0 ‚Üí ‚úÖ Healthy\n",
    "3.0 ‚Üí ‚ö† Could mean inefficient capital use\n",
    "Ideal zone: 1.5 ‚Äì 2.5\n",
    "\n",
    "üíµ 2Ô∏è‚É£ Cash Ratio\n",
    "(Cash / Current Liabilities)\n",
    "< 0.2 ‚Üí üö® Weak liquidity\n",
    "0.2 ‚Äì 0.5 ‚Üí Moderate\n",
    "0.5 ‚Üí Strong liquidity\n",
    "Note: Very high cash is uncommon in capital-intensive industries.\n",
    "\n",
    "üìâ 3Ô∏è‚É£ Debt to Equity\n",
    "< 0.5 ‚Üí Conservative\n",
    "0.5 ‚Äì 1.5 ‚Üí Normal corporate leverage\n",
    "1.5 ‚Äì 2.5 ‚Üí Aggressive\n",
    "2.5 ‚Üí üö® High financial risk\n",
    "Banks get uncomfortable above 2.0\n",
    "\n",
    "üè¶ 4Ô∏è‚É£ Debt to Assets\n",
    "< 0.4 ‚Üí Low leverage\n",
    "0.4 ‚Äì 0.6 ‚Üí Moderate\n",
    "0.6 ‚Üí High risk\n",
    "\n",
    "üìà 5Ô∏è‚É£ Net Profit Margin\n",
    "< 0 ‚Üí üö® Loss-making\n",
    "0 ‚Äì 5% ‚Üí Thin margins\n",
    "5 ‚Äì 15% ‚Üí Healthy\n",
    "15% ‚Üí Strong\n",
    "Depends heavily on industry.\n",
    "\n",
    "üìä 6Ô∏è‚É£ ROA (Return on Assets)\n",
    "< 0 ‚Üí Risk\n",
    "0 ‚Äì 5% ‚Üí Weak\n",
    "5 ‚Äì 10% ‚Üí Good\n",
    "10% ‚Üí Strong\n",
    "\n",
    "üèõ 7Ô∏è‚É£ ROE (Return on Equity)\n",
    "< 0 ‚Üí Risk\n",
    "5 ‚Äì 15% ‚Üí Acceptable\n",
    "15 ‚Äì 25% ‚Üí Strong\n",
    "25% ‚Üí Very strong (or over-leveraged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df42b9fc-1c58-42fd-afbf-e10f9bd3434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "764f8f42-13dc-4043-b1fa-3dc56146e920",
   "metadata": {},
   "source": [
    "üß† What This Tells Us\n",
    "\n",
    "Major columns (Assets, Liabilities, Revenue, NetIncome, Equity)\n",
    "‚Üí 0 missing ‚úÖ\n",
    "\n",
    "Ratio features:\n",
    "current_ratio ‚Üí ~1.4k missing\n",
    "cash_ratio ‚Üí ~3.2k missing\n",
    "free_cash_flow ‚Üí ~3.5k missing\n",
    "debt_to_assets ‚Üí only 86 missing (excellent)\n",
    "ROA ‚Üí only 86 missing (excellent)\n",
    "\n",
    "This is normal because:\n",
    "Some firms don‚Äôt report current assets separately\n",
    "Some don‚Äôt report capex clearly\n",
    "Some don‚Äôt report detailed cash components\n",
    "This is real-world financial data behavior."
   ]
  },
  {
   "cell_type": "raw",
   "id": "42eb8685-09ac-4538-897a-2cb196f9771d",
   "metadata": {},
   "source": [
    "üéØ Decision: How We Handle Missing Values\n",
    "\n",
    "We do NOT drop rows anymore.\n",
    "That would shrink dataset too much.\n",
    "\n",
    "Instead:\n",
    "\n",
    "Strategy:\n",
    "Keep all rows\n",
    "Impute missing ratio values with median\n",
    "Later standardize features\n",
    "\n",
    "Why median?\n",
    "Because financial ratios are skewed. Mean is dangerous."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c09b89-ecc8-46c7-b291-43164f843f4f",
   "metadata": {},
   "source": [
    "### Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcabbe8-c321-4c96-a1c7-0e2c64c37142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# Fill missing numeric values with median\n",
    "# ---------------------------------------\n",
    "\n",
    "numeric_cols = feature_df.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "\n",
    "for col in numeric_cols:\n",
    "    feature_df[col] = feature_df[col].fillna(feature_df[col].median())\n",
    "\n",
    "print(\"Remaining missing values:\")\n",
    "print(feature_df.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064651c2-037c-44f3-8be2-9c8decbb1513",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d641b71-fb08-4dd7-814f-da0337c9d5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "72de3db8-d872-4da1-b4eb-9793112761ee",
   "metadata": {},
   "source": [
    "This is the most important modeling decision.\n",
    "\n",
    "Right now, we only have financial ratios.\n",
    "We don‚Äôt yet have a ‚Äúrisk label‚Äù.\n",
    "\n",
    "We must create a composite financial risk score from domain logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b91253f-d595-4bfd-8f5e-cc377db4579d",
   "metadata": {},
   "source": [
    "### Create Composite Risk Score"
   ]
  },
  {
   "cell_type": "raw",
   "id": "29047dc9-fd75-4b5f-8170-bdac499d11b2",
   "metadata": {},
   "source": [
    "We‚Äôll build a weighted risk score based on financial stress signals.\n",
    "\n",
    "High risk signals:\n",
    "\n",
    "High debt_to_equity\n",
    "High debt_to_assets\n",
    "Low current_ratio\n",
    "Low cash_ratio\n",
    "Negative net_profit_margin\n",
    "Negative ROA\n",
    "Negative ROE\n",
    "Negative free_cash_flow\n",
    "Low operating_cf_ratio"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aa9844ca-b5e5-438c-b616-3e13e49cb45c",
   "metadata": {},
   "source": [
    "üß† Strategy\n",
    "\n",
    "We will:\n",
    "\n",
    "Standardize selected risk features\n",
    "Assign directional risk weights\n",
    "Combine into one risk_score\n",
    "Convert into 3 categories:\n",
    "    0 ‚Üí Low Risk\n",
    "    1 ‚Üí Medium Risk\n",
    "    2 ‚Üí High Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1819e8f-6d26-4c5d-883e-c93124800134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "risk_features = [\n",
    "    \"debt_to_equity\",\n",
    "    \"debt_to_assets\",\n",
    "    \"current_ratio\",\n",
    "    \"cash_ratio\",\n",
    "    \"net_profit_margin\",\n",
    "    \"return_on_assets\",\n",
    "    \"return_on_equity\",\n",
    "    \"free_cash_flow\",\n",
    "    \"operating_cf_ratio\"\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_values = scaler.fit_transform(feature_df[risk_features])\n",
    "\n",
    "scaled_df = pd.DataFrame(scaled_values, columns=risk_features)\n",
    "\n",
    "feature_df[\"risk_score\"] = (\n",
    "    scaled_df[\"debt_to_equity\"] +\n",
    "    scaled_df[\"debt_to_assets\"] -\n",
    "    scaled_df[\"current_ratio\"] -\n",
    "    scaled_df[\"cash_ratio\"] -\n",
    "    scaled_df[\"net_profit_margin\"] -\n",
    "    scaled_df[\"return_on_assets\"] -\n",
    "    scaled_df[\"return_on_equity\"] -\n",
    "    scaled_df[\"free_cash_flow\"] -\n",
    "    scaled_df[\"operating_cf_ratio\"]\n",
    ")\n",
    "\n",
    "feature_df[\"risk_score\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926e4ded-7c43-47f7-a609-810c1da3bbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f32763-9194-45a1-bacb-69f9490af106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "risk_features = [\n",
    "    \"debt_to_equity\",\n",
    "    \"debt_to_assets\",\n",
    "    \"current_ratio\",\n",
    "    \"cash_ratio\",\n",
    "    \"net_profit_margin\",\n",
    "    \"return_on_assets\",\n",
    "    \"return_on_equity\",\n",
    "    \"free_cash_flow\",\n",
    "    \"operating_cf_ratio\"\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_values = scaler.fit_transform(feature_df[risk_features])\n",
    "\n",
    "scaled_df = pd.DataFrame(scaled_values, columns=risk_features)\n",
    "\n",
    "feature_df[\"risk_score\"] = (\n",
    "    scaled_df[\"debt_to_equity\"] +\n",
    "    scaled_df[\"debt_to_assets\"] -\n",
    "    scaled_df[\"current_ratio\"] -\n",
    "    scaled_df[\"cash_ratio\"] -\n",
    "    scaled_df[\"net_profit_margin\"] -\n",
    "    scaled_df[\"return_on_assets\"] -\n",
    "    scaled_df[\"return_on_equity\"] -\n",
    "    scaled_df[\"free_cash_flow\"] -\n",
    "    scaled_df[\"operating_cf_ratio\"]\n",
    ")\n",
    "\n",
    "feature_df[\"risk_score\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4016daf-8600-44d0-9606-51706567613c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ba831fbe-39c0-4aa0-9c83-32d6d00e2497",
   "metadata": {},
   "source": [
    "Good ‚Äî now this makes sense.\n",
    "\n",
    "Important observation:\n",
    "\n",
    "feature_df.shape = (7970, 25) ‚úÖ correct\n",
    "\n",
    "But risk_score.describe() shows count = 256\n",
    "\n",
    "That means:\n",
    "\n",
    "üëâ Only 256 rows have valid numeric values in risk_score\n",
    "üëâ The remaining rows are NaN\n",
    "\n",
    "This happened because of this line:\n",
    "\n",
    "scaled_df = pd.DataFrame(scaled_values, columns=risk_features)\n",
    "\n",
    "\n",
    "You created scaled_df without preserving index alignment.\n",
    "\n",
    "So when assigning:\n",
    "\n",
    "feature_df[\"risk_score\"] = ...\n",
    "\n",
    "\n",
    "Pandas aligned by index, and only matching index rows were filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3513fc72-6247-450c-b807-202c7e8ed455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "risk_features = [\n",
    "    \"debt_to_equity\",\n",
    "    \"debt_to_assets\",\n",
    "    \"current_ratio\",\n",
    "    \"cash_ratio\",\n",
    "    \"net_profit_margin\",\n",
    "    \"return_on_assets\",\n",
    "    \"return_on_equity\",\n",
    "    \"free_cash_flow\",\n",
    "    \"operating_cf_ratio\"\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_values = scaler.fit_transform(feature_df[risk_features])\n",
    "\n",
    "# Preserve original index\n",
    "scaled_df = pd.DataFrame(\n",
    "    scaled_values,\n",
    "    columns=risk_features,\n",
    "    index=feature_df.index\n",
    ")\n",
    "\n",
    "feature_df[\"risk_score\"] = (\n",
    "    scaled_df[\"debt_to_equity\"] +\n",
    "    scaled_df[\"debt_to_assets\"] -\n",
    "    scaled_df[\"current_ratio\"] -\n",
    "    scaled_df[\"cash_ratio\"] -\n",
    "    scaled_df[\"net_profit_margin\"] -\n",
    "    scaled_df[\"return_on_assets\"] -\n",
    "    scaled_df[\"return_on_equity\"] -\n",
    "    scaled_df[\"free_cash_flow\"] -\n",
    "    scaled_df[\"operating_cf_ratio\"]\n",
    ")\n",
    "\n",
    "feature_df[\"risk_score\"].describe()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "63dab76f-727e-4cdb-aae1-27ad49b9bb3e",
   "metadata": {},
   "source": [
    "üéØ Expected Result\n",
    "\n",
    "Now:\n",
    "count should be ~7970\n",
    "Mean ‚âà 0\n",
    "Std ‚âà 2‚Äì4 range depending on distribution\n",
    "No collapse to 256\n",
    "\n",
    "This is a proper continuous risk score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18c588e-c35e-4db3-8952-9c1a227f39c1",
   "metadata": {},
   "source": [
    "### Create Risk Categories (Stable Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fe1a77-44a9-4d9a-bddf-b8d45637bec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute percentile thresholds\n",
    "low_thresh = feature_df[\"risk_score\"].quantile(0.33)\n",
    "high_thresh = feature_df[\"risk_score\"].quantile(0.66)\n",
    "\n",
    "print(\"Low threshold:\", low_thresh)\n",
    "print(\"High threshold:\", high_thresh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139d1bd3-3f1d-4161-8258-18938abb10a8",
   "metadata": {},
   "source": [
    "### Assign Risk Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d8c752-e105-489e-992b-a2aaf283411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_risk(x):\n",
    "    if x <= low_thresh:\n",
    "        return 0   # Low Risk\n",
    "    elif x <= high_thresh:\n",
    "        return 1   # Medium Risk\n",
    "    else:\n",
    "        return 2   # High Risk\n",
    "\n",
    "feature_df[\"risk_category\"] = feature_df[\"risk_score\"].apply(assign_risk)\n",
    "\n",
    "feature_df[\"risk_category\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a20a7cf6-f08b-46d0-9b59-887751063488",
   "metadata": {},
   "source": [
    "Perfect. That‚Äôs exactly what we want.\n",
    "\n",
    "Distribution:\n",
    "\n",
    "0 (Low Risk) ‚Üí 2630\n",
    "1 (Medium Risk) ‚Üí 2631\n",
    "2 (High Risk) ‚Üí 2709\n",
    "\n",
    "Almost perfectly balanced.\n",
    "Total ‚âà 7,970 rows ‚Äî dataset intact.\n",
    "\n",
    "You now have:\n",
    "Real SEC financial data\n",
    "Engineered financial ratios\n",
    "Composite risk score\n",
    "Balanced 3-class target variable\n",
    "\n",
    "This is a legitimate supervised ML setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a66939-d467-4576-82a0-7a5c494e0e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212e0f6a-f9f8-434f-b6fb-e8e65bff99f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee5c5c8-3254-4fd6-965a-6566a4abe77c",
   "metadata": {},
   "source": [
    "## saving CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce5327b-f480-4df9-92db-0f1892e3e863",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.to_csv(\n",
    "    r\"D:\\Resume\\KPMG\\Automated Financial Risk Scoring Platform (Machine Learning + LLM)\\final_engineered_financial_dataset.csv\",\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31d17de-9720-4124-b190-d74a2ba0e6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.path.exists(\n",
    "    r\"D:\\Resume\\KPMG\\Automated Financial Risk Scoring Platform (Machine Learning + LLM)\\final_engineered_financial_dataset.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fd7f88-5aa4-464e-83da-edb0a098c997",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9ce846-d31f-45a9-9ead-7d7fc9cd8169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_df[\"risk_category\"].value_counts().plot(kind=\"bar\")\n",
    "plt.title(\"Risk Category Distribution\")\n",
    "plt.xlabel(\"Risk Category\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cebc2bd-c585-42d9-bd39-1f71fdfb825c",
   "metadata": {},
   "source": [
    "### Risk Score Distribution (Understand Spread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bbcfd3-ff91-4187-a5ff-4a412c90cf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "feature_df[\"risk_score\"].hist(bins=50)\n",
    "plt.title(\"Distribution of Risk Score\")\n",
    "plt.xlabel(\"Risk Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d1c82cb2-2806-4667-8447-db3306ae0c6b",
   "metadata": {},
   "source": [
    "üîé What This Distribution Shows\n",
    "\n",
    "Huge spike around 0 ‚Üí Most companies are financially average.\n",
    "Long left tail (~ -180) ‚Üí Extremely strong firms (very safe).\n",
    "Long right tail (~ +100) ‚Üí Extremely risky firms.\n",
    "This is normal in financial datasets:\n",
    "Majority are stable.\n",
    "Few are extreme outliers.\n",
    "\n",
    "‚ö† Important Observation\n",
    "\n",
    "The spike is very tight around 0.\n",
    "That means:\n",
    "Most companies cluster tightly in middle\n",
    "Risk separation is happening mainly through tails\n",
    "That‚Äôs actually good for ML ‚Äî model will learn nonlinear separation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9967e7-27a7-49fc-b057-f24ef305667b",
   "metadata": {},
   "source": [
    "### Boxplot of Risk Score (Outlier Detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9885e8-a288-47d4-ad68-22b3095799ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.boxplot(feature_df[\"risk_score\"])\n",
    "plt.title(\"Risk Score Boxplot\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49f2f49f-8e53-441a-abd8-8492404b57ea",
   "metadata": {},
   "source": [
    "üîé What the Boxplot Tells You\n",
    "\n",
    "Median ‚âà 0 ‚Üí expected (standardized composite score)\n",
    "Very tight interquartile range ‚Üí most firms cluster around average\n",
    "Many extreme outliers on both sides\n",
    "+100 ‚Üí highly distressed firms\n",
    "-180 ‚Üí extremely strong firms\n",
    "This is normal in financial data.\n",
    "Finance always has heavy tails.\n",
    "\n",
    "‚ö† Important Question\n",
    "\n",
    "Should we remove outliers?\n",
    "Answer: No.\n",
    "\n",
    "Why?\n",
    "XGBoost handles outliers well\n",
    "Extreme financial distress is valuable signal.\n",
    "Removing them weakens model realism.\n",
    "We keep them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ac76dc-a15a-4da0-9503-8b206f7595ad",
   "metadata": {},
   "source": [
    "### Feature Distribution (Example: Debt to Equity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6df41c-a2f0-407c-adca-b10442cc75e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "feature_df[\"debt_to_equity\"].hist(bins=50)\n",
    "plt.title(\"Debt to Equity Distribution\")\n",
    "plt.xlabel(\"Debt to Equity\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cb6b25cb-6d23-498e-8466-814cbb7f9a1d",
   "metadata": {},
   "source": [
    "üö® Major Observation\n",
    "\n",
    "Debt-to-Equity is extremely skewed.\n",
    "\n",
    "You have:\n",
    "Massive spike near 0\n",
    "Extreme values going up to 3.5 √ó 10‚Å∑\n",
    "That is not economically realistic for corporate leverage.\n",
    "This happens because:\n",
    "Some companies have very tiny equity\n",
    "Division by very small number explodes ratio\n",
    "Some firms may even have near-zero equity\n",
    "That creates extreme leverage values.\n",
    "\n",
    "‚ö† Important Question\n",
    "Is this a problem?\n",
    "\n",
    "For ML:\n",
    "XGBoost can handle skewnes\n",
    "But extreme ratios can dominate scaling\n",
    "And distort risk_score construction\n",
    "So we need to control this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99ac172-8cec-4660-8f93-553c5022083b",
   "metadata": {},
   "source": [
    "### Professional Fix ‚Äî Cap Extreme Ratios (Winsorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b772c3-3c08-4c5b-b203-8403a3e84544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cap extreme leverage values at 1st and 99th percentile\n",
    "\n",
    "for col in [\"debt_to_equity\", \"debt_to_assets\"]:\n",
    "    lower = feature_df[col].quantile(0.01)\n",
    "    upper = feature_df[col].quantile(0.99)\n",
    "    feature_df[col] = feature_df[col].clip(lower, upper)\n",
    "\n",
    "feature_df[\"debt_to_equity\"].describe()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "630cec5d-6036-47b3-ad22-c52346b7cc5d",
   "metadata": {},
   "source": [
    "Good. Now we see the real picture.\n",
    "\n",
    "Even after capping at 1st and 99th percentile:\n",
    "Mean = 2,421\n",
    "Max = 134,768\n",
    "Std = 15,255\n",
    "This is still extremely skewed.\n",
    "\n",
    "Why?\n",
    "Because percentile clipping still allows huge values if distribution itself is extremely heavy-tailed.\n",
    "This is common in finance when:\n",
    "Equity is tiny\n",
    "Firms have accumulated losses\n",
    "Negative equity exists\n",
    "\n",
    "üö® Proper Financial Fix\n",
    "For leverage ratios like Debt-to-Equity:\n",
    "\n",
    "üëâ We should use log transformation\n",
    "üëâ Or use a bounded transformation\n",
    "\n",
    "Because raw D/E is unstable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2742b2-945f-4836-a44e-7331a0c29366",
   "metadata": {},
   "source": [
    "### Professional Fix ‚Äî Log Transform (Stable Version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8247b611-a6e0-48a7-bec9-5ff92e9b1445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "feature_df[\"debt_to_equity\"] = np.sign(feature_df[\"debt_to_equity\"]) * \\\n",
    "                               np.log1p(np.abs(feature_df[\"debt_to_equity\"]))\n",
    "\n",
    "feature_df[\"debt_to_equity\"].describe()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bfcd609a-388c-482c-b98a-4f8a3082ea57",
   "metadata": {},
   "source": [
    "Excellent.\n",
    "\n",
    "Now this is financially sane.\n",
    "\n",
    "Before:\n",
    "Max = 134,768 (unusable)\n",
    "Std = 15,255 (distorted)\n",
    "\n",
    "Now:\n",
    "Max ‚âà 11.81\n",
    "Min ‚âà -7.10\n",
    "Std ‚âà 3.11\n",
    "\n",
    "This is stable and ML-friendly.\n",
    "You just handled a real-world financial data issue properly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fd730b-fa75-49f7-88dc-00fb9bb57118",
   "metadata": {},
   "source": [
    "Important: We Must Recompute Risk Score\n",
    "\n",
    "Because we changed debt_to_equity, the previous risk_score is no longer valid.\n",
    "\n",
    "So now we recompute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde405aa-0e1b-4c7b-b0ae-1c244f64ddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "risk_features = [\n",
    "    \"debt_to_equity\",\n",
    "    \"debt_to_assets\",\n",
    "    \"current_ratio\",\n",
    "    \"cash_ratio\",\n",
    "    \"net_profit_margin\",\n",
    "    \"return_on_assets\",\n",
    "    \"return_on_equity\",\n",
    "    \"free_cash_flow\",\n",
    "    \"operating_cf_ratio\"\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_values = scaler.fit_transform(feature_df[risk_features])\n",
    "\n",
    "scaled_df = pd.DataFrame(\n",
    "    scaled_values,\n",
    "    columns=risk_features,\n",
    "    index=feature_df.index\n",
    ")\n",
    "\n",
    "feature_df[\"risk_score\"] = (\n",
    "    scaled_df[\"debt_to_equity\"] +\n",
    "    scaled_df[\"debt_to_assets\"] -\n",
    "    scaled_df[\"current_ratio\"] -\n",
    "    scaled_df[\"cash_ratio\"] -\n",
    "    scaled_df[\"net_profit_margin\"] -\n",
    "    scaled_df[\"return_on_assets\"] -\n",
    "    scaled_df[\"return_on_equity\"] -\n",
    "    scaled_df[\"free_cash_flow\"] -\n",
    "    scaled_df[\"operating_cf_ratio\"]\n",
    ")\n",
    "\n",
    "feature_df[\"risk_score\"].describe()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f27c9bc-9309-46e1-aed8-8931d391bf1f",
   "metadata": {},
   "source": [
    "Good. That‚Äôs acceptable.\n",
    "\n",
    "Interpretation:\n",
    "Count = 7,970 ‚úÖ\n",
    "Mean ‚âà 0 ‚úÖ\n",
    "Std ‚âà 3.42 (reasonable spread)\n",
    "Min = -176 (extremely strong firms)\n",
    "Max = 77 (very risky firms)\n",
    "\n",
    "Heavy tails still exist ‚Äî but that‚Äôs normal in financial data.\n",
    "Now we recreate risk categories cleanly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9092928a-a815-4ebe-a088-a2fef26375e1",
   "metadata": {},
   "source": [
    "### Recreate Risk Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc785d8-cab6-49b5-8f6c-388cbcfe6c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompute thresholds\n",
    "low_thresh = feature_df[\"risk_score\"].quantile(0.33)\n",
    "high_thresh = feature_df[\"risk_score\"].quantile(0.66)\n",
    "\n",
    "print(\"Low threshold:\", low_thresh)\n",
    "print(\"High threshold:\", high_thresh)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be6f74db-1aa3-4f71-93b0-b927edb5ec9e",
   "metadata": {},
   "source": [
    "Good. Those thresholds look much healthier now:\n",
    "\n",
    "Low threshold ‚âà -0.43\n",
    "High threshold ‚âà -0.10\n",
    "\n",
    "Now the separation range is wider (not collapsing near zero like before). That‚Äôs a sign your transformation fixed leverage distortion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81efec14-b6b0-48f9-9a21-55830e57c815",
   "metadata": {},
   "source": [
    "### Final Step ‚Äî Assign Risk Categories Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b6e2f8-c14d-4fab-bb2d-c032b8b11c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_risk(x):\n",
    "    if x <= low_thresh:\n",
    "        return 0   # Low Risk\n",
    "    elif x <= high_thresh:\n",
    "        return 1   # Medium Risk\n",
    "    else:\n",
    "        return 2   # High Risk\n",
    "\n",
    "feature_df[\"risk_category\"] = feature_df[\"risk_score\"].apply(assign_risk)\n",
    "\n",
    "feature_df[\"risk_category\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3920db31-13d3-4adf-9c37-117f00731c0e",
   "metadata": {},
   "source": [
    "Perfect. That‚Äôs clean and balanced.\n",
    "\n",
    "Low Risk (0) ‚Üí 2630\n",
    "Medium Risk (1) ‚Üí 2630\n",
    "High Risk (2) ‚Üí 2710\n",
    "\n",
    "Dataset intact (~7970 rows).\n",
    "Risk logic stable.\n",
    "Outlier distortion handled.\n",
    "\n",
    "You now have a properly engineered financial risk dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e83a532-95a1-404f-b0b6-e7b36e6ec84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "feature_df[\"debt_to_equity\"].hist(bins=50)\n",
    "plt.title(\"Debt to Equity Distribution\")\n",
    "plt.xlabel(\"Debt to Equity\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b3426b-e1f9-4653-be44-12408a2fbdbd",
   "metadata": {},
   "source": [
    "### Final Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9835086-36de-4667-9b20-aefd6fd753df",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.groupby(\"risk_category\")[\n",
    "    [\"debt_to_equity\", \"current_ratio\", \"return_on_assets\"]\n",
    "].mean()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6af9ea60-efdf-460e-b98a-6cd0ce018bb1",
   "metadata": {},
   "source": [
    "üìä Group Means Interpretation\n",
    "\n",
    "üîπ Risk 0 (Low Risk)\n",
    "Extremely strong liquidity\n",
    "Strong profitability\n",
    "Low leverage\n",
    "\n",
    "Very safe firms. Makes sense.\n",
    "\n",
    "But current_ratio = 4557 is suspiciously huge.\n",
    "\n",
    "üîπ Risk 1 (Medium Risk)\n",
    "Moderate leverage\n",
    "Reasonable liquidity\n",
    "Near breakeven profitability\n",
    "\n",
    "Reasonable middle group.\n",
    "\n",
    "üîπ Risk 2 (High Risk)\n",
    "High leverage\n",
    "Lower liquidity\n",
    "Severe negative profitability\n",
    "\n",
    "This is clearly distressed.\n",
    "\n",
    "üö® One Problem Detected\n",
    "Current ratio for Risk 0 = 4557\n",
    "That is unrealistically high.\n",
    "\n",
    "This means:\n",
    "Some companies have near-zero current liabilities\n",
    "Ratio exploded\n",
    "This can distort modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b8001a-a5a9-45c1-8406-b215a2919565",
   "metadata": {},
   "source": [
    "### professional Fix ‚Äî Log Transform Current Ratiom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426f91b6-c5f5-4b53-ac6d-8e5b76bcc491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "feature_df[\"current_ratio\"] = np.log1p(feature_df[\"current_ratio\"])\n",
    "feature_df[\"cash_ratio\"] = np.log1p(feature_df[\"cash_ratio\"])\n",
    "\n",
    "feature_df[[\"current_ratio\", \"cash_ratio\"]].describe()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "05b44b7d-41a0-4a28-947a-259cda76f157",
   "metadata": {},
   "source": [
    "Good. This is much better.\n",
    "\n",
    "Now:\n",
    "Median current_ratio ‚âà 0.83 (log scale)\n",
    "Max ‚âà 16.29 (compressed from thousands)\n",
    "Distribution looks stable\n",
    "No absurd explosion like 4557 anymore\n",
    "This is model-ready behavior.\n",
    "\n",
    "‚ö† One small thing:\n",
    "Count is 7955 and 7957, not 7970.\n",
    "That means a few NaNs appeared after log transform (likely from negative values slightly below -1 due to earlier imputation).\n",
    "That‚Äôs fine ‚Äî we will handle it properly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dd5129-41df-4944-97bd-b9e0502f1f1d",
   "metadata": {},
   "source": [
    "### Fill Any New NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22224c0-fb66-43de-8966-40e55bab99f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df[\"current_ratio\"] = feature_df[\"current_ratio\"].fillna(feature_df[\"current_ratio\"].median())\n",
    "feature_df[\"cash_ratio\"] = feature_df[\"cash_ratio\"].fillna(feature_df[\"cash_ratio\"].median())\n",
    "\n",
    "feature_df[[\"current_ratio\", \"cash_ratio\"]].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2cffc4-a0c9-4440-8082-14244adab9c5",
   "metadata": {},
   "source": [
    "### Recompute Risk Score (Final Version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627dfe93-f190-4bc1-aef7-b12878b3f88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "risk_features = [\n",
    "    \"debt_to_equity\",\n",
    "    \"debt_to_assets\",\n",
    "    \"current_ratio\",\n",
    "    \"cash_ratio\",\n",
    "    \"net_profit_margin\",\n",
    "    \"return_on_assets\",\n",
    "    \"return_on_equity\",\n",
    "    \"free_cash_flow\",\n",
    "    \"operating_cf_ratio\"\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_values = scaler.fit_transform(feature_df[risk_features])\n",
    "\n",
    "scaled_df = pd.DataFrame(\n",
    "    scaled_values,\n",
    "    columns=risk_features,\n",
    "    index=feature_df.index\n",
    ")\n",
    "\n",
    "feature_df[\"risk_score\"] = (\n",
    "    scaled_df[\"debt_to_equity\"] +\n",
    "    scaled_df[\"debt_to_assets\"] -\n",
    "    scaled_df[\"current_ratio\"] -\n",
    "    scaled_df[\"cash_ratio\"] -\n",
    "    scaled_df[\"net_profit_margin\"] -\n",
    "    scaled_df[\"return_on_assets\"] -\n",
    "    scaled_df[\"return_on_equity\"] -\n",
    "    scaled_df[\"free_cash_flow\"] -\n",
    "    scaled_df[\"operating_cf_ratio\"]\n",
    ")\n",
    "\n",
    "feature_df[\"risk_score\"].describe()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "357186ca-ca3b-49ed-b406-b883324e7ea7",
   "metadata": {},
   "source": [
    "Excellent. This is now much healthier.\n",
    "\n",
    "Compare with earlier:\n",
    "\n",
    "Before:\n",
    "Min ‚âà -176\n",
    "25% ‚âà -0.48\n",
    "75% ‚âà 0.12\n",
    "\n",
    "Now:\n",
    "Min ‚âà -93 (tails compressed)\n",
    "25% ‚âà -0.95\n",
    "75% ‚âà 0.97\n",
    "Median ‚âà 0.18\n",
    "\n",
    "The interquartile spread is now wider and more meaningful.\n",
    "Your liquidity distortion is fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775b2b13-a33b-4b7b-8b53-925ac8d1fb31",
   "metadata": {},
   "source": [
    "### Now Recreate Risk Categories (Final Clean Version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e4813d-7558-45e0-a7f5-ce36ae1474f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute thresholds again\n",
    "low_thresh = feature_df[\"risk_score\"].quantile(0.33)\n",
    "high_thresh = feature_df[\"risk_score\"].quantile(0.66)\n",
    "\n",
    "print(\"Low threshold:\", low_thresh)\n",
    "print(\"High threshold:\", high_thresh)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1db2cdb5-db50-4fa1-af2f-44ce296004a1",
   "metadata": {},
   "source": [
    "Good. These thresholds look much more realistic now:\n",
    "\n",
    "Low threshold ‚âà -0.38\n",
    "High threshold ‚âà 0.64\n",
    "Notice the separation is now symmetric around zero and properly spread. This means your transformations worked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7716750-480a-4737-b516-946f76e7d047",
   "metadata": {},
   "source": [
    "### Final Label Assignment (Clean Version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd3b1b8-b8a8-4206-bf7f-8e2f5b7fab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_risk(x):\n",
    "    if x <= low_thresh:\n",
    "        return 0   # Low Risk\n",
    "    elif x <= high_thresh:\n",
    "        return 1   # Medium Risk\n",
    "    else:\n",
    "        return 2   # High Risk\n",
    "\n",
    "feature_df[\"risk_category\"] = feature_df[\"risk_score\"].apply(assign_risk)\n",
    "\n",
    "feature_df[\"risk_category\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "48c733ff-6f3d-4a6a-86b0-acfe30b3c6b6",
   "metadata": {},
   "source": [
    "Perfect. That‚Äôs stable and balanced.\n",
    "\n",
    "Low Risk (0) ‚Üí 2630\n",
    "Medium Risk (1) ‚Üí 2630\n",
    "High Risk (2) ‚Üí 2710\n",
    "\n",
    "Dataset: 7,970 rows\n",
    "Outliers controlled\n",
    "Ratios stabilized\n",
    "Risk labeling economically sensible\n",
    "\n",
    "Your financial engineering phase is now solid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72570fb3-0285-43fd-9a54-c39d354781b9",
   "metadata": {},
   "source": [
    "### Correlation Heatmap (Very Important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e2132d-2f9c-4614-b588-0523cf92bb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(\n",
    "    feature_df[[\n",
    "        \"debt_to_equity\",\n",
    "        \"debt_to_assets\",\n",
    "        \"current_ratio\",\n",
    "        \"cash_ratio\",\n",
    "        \"net_profit_margin\",\n",
    "        \"return_on_assets\",\n",
    "        \"return_on_equity\",\n",
    "        \"free_cash_flow\",\n",
    "        \"operating_cf_ratio\"\n",
    "    ]].corr(),\n",
    "    annot=True\n",
    ")\n",
    "plt.title(\"Feature Correlation Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6433724-34dc-4123-8b2c-21c702de7bb7",
   "metadata": {},
   "source": [
    "üîé Correlation Matrix Analysis\n",
    "1Ô∏è‚É£ No Dangerous Multicollinearity\n",
    "\n",
    "Most correlations are near 0.\n",
    "That‚Äôs good.\n",
    "\n",
    "You don‚Äôt have redundant features dominating each other.\n",
    "\n",
    "2Ô∏è‚É£ Strong Correlation: current_ratio & cash_ratio\n",
    "They are strongly positively correlated (~0.7+ visually).\n",
    "That makes sense\n",
    "Cash is part of current assets.\n",
    "Both measure liquidity\n",
    "This is acceptable.\n",
    "Tree-based models like XGBoost handle correlated features well.\n",
    "No need to drop either.\n",
    "\n",
    "3Ô∏è‚É£ Debt-to-Assets & ROA (negative correlation)\n",
    "We see negative correlation there.\n",
    "That is financially logical:\n",
    "More leverage ‚Üí lower returns (often)\n",
    "That‚Äôs good. It means data is behaving economically.\n",
    "\n",
    "üéØ Conclusion\n",
    "\n",
    "‚úî No extreme multicollinearity\n",
    "‚úî No accidental feature duplication\n",
    "‚úî Financial logic preserved\n",
    "‚úî Dataset stable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a11ff3-ab95-4a8f-9742-0f3e58d31f69",
   "metadata": {},
   "source": [
    "### Feature Behavior Across Risk Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1803edbf-7061-435c-b605-d61268f198d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "feature_df.boxplot(column=\"debt_to_equity\", by=\"risk_category\")\n",
    "plt.title(\"Debt to Equity by Risk Category\")\n",
    "plt.suptitle(\"\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7685008d-c4aa-4705-a635-12e4b676beae",
   "metadata": {},
   "source": [
    "üìä Debt-to-Equity by Risk Category\n",
    "üîπ Risk 0 (Low Risk)\n",
    "Median around ~0 or slightly negative\n",
    "Mostly low leverage\n",
    "Some negative equity firms (possible strong cash firms or accounting effects)\n",
    "\n",
    "üîπ Risk 1 (Medium Risk)\n",
    "Median slightly positive\n",
    "Moderate leverage\n",
    "Wider spread than low-risk group\n",
    "\n",
    "üîπ Risk 2 (High Risk)\n",
    "Clearly highest median leverage\n",
    "Much wider spread\n",
    "Strong upward skew\n",
    "This is economically correct.\n",
    "High risk firms ‚Üí higher leverage.\n",
    "That validates your composite scoring logic.\n",
    "\n",
    "üî• This Is Very Important\n",
    "Your labeling is not random.\n",
    "The feature behavior aligns with financial theory.\n",
    "\n",
    "That means:\n",
    "Your target variable construction is valid\n",
    "The ML model will learn meaningful patterns\n",
    "This is interview-ready logic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae57d8fa-201a-4aae-9d86-15ca4e57f802",
   "metadata": {},
   "source": [
    "### what we changed"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d4800f5-1754-49ed-aa14-c87ddb277ad3",
   "metadata": {},
   "source": [
    "What We Modified\n",
    "\n",
    "Debt-to-Equity\n",
    "Originally exploded due to tiny equity values.\n",
    "Applied log transformation.\n",
    "Made it numerically stable and economically interpretable.\n",
    "\n",
    "Current Ratio & Cash Ratio\n",
    "Extremely large values due to near-zero liabilities.\n",
    "Applied log transform.\n",
    "Reduced distortion.\n",
    "\n",
    "Risk Score\n",
    "Recomputed after transformations.\n",
    "Now reflects realistic financial separation.\n",
    "\n",
    "Risk Category\n",
    "Rebuilt using updated thresholds.\n",
    "Now financially consistent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bdd8da-1f80-4de3-b3ca-876da809b484",
   "metadata": {},
   "source": [
    "### save new CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b130dd-f5ba-4b89-8b10-bbf5b1be1b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.to_csv(\n",
    "    r\"D:\\Resume\\KPMG\\Automated Financial Risk Scoring Platform (Machine Learning + LLM)\\engineered_financial_dataset_v2.csv\",\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40fccda-2b61-4eed-abe8-51db031a5645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.path.exists(\n",
    "    r\"D:\\Resume\\KPMG\\Automated Financial Risk Scoring Platform (Machine Learning + LLM)\\engineered_financial_dataset_v2.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a689a2-a263-462d-bfd9-398f88dcd292",
   "metadata": {},
   "source": [
    "## importing the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c75368c-b8d8-4fc0-8e89-ca881fb62d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "feature_df = pd.read_csv(\n",
    "    r\"D:\\Resume\\KPMG\\Automated Financial Risk Scoring Platform (Machine Learning + LLM)\\engineered_financial_dataset_v2.csv\"\n",
    ")\n",
    "\n",
    "print(\"Dataset loaded.\")\n",
    "print(\"Shape:\", feature_df.shape)\n",
    "feature_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16e6df6-bb3e-4a1a-b760-d73b56221dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0176c33a-5487-46d0-b249-059de9ab7905",
   "metadata": {},
   "source": [
    "## modeling phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e702ed0-7e1f-4ca4-9cf4-cd0f3e458005",
   "metadata": {},
   "source": [
    "### Prepare X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae568fe4-1be2-4b9f-b13d-bb17e00f02ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features for modeling\n",
    "model_features = [\n",
    "    \"debt_to_equity\",\n",
    "    \"debt_to_assets\",\n",
    "    \"current_ratio\",\n",
    "    \"cash_ratio\",\n",
    "    \"net_profit_margin\",\n",
    "    \"return_on_assets\",\n",
    "    \"return_on_equity\",\n",
    "    \"free_cash_flow\",\n",
    "    \"operating_cf_ratio\"\n",
    "]\n",
    "\n",
    "X = feature_df[model_features]\n",
    "y = feature_df[\"risk_category\"]\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ab44e1-f812-4b2f-98ff-807a0026f3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145f0e91-cb09-43c1-a37e-e59a3b2e79e6",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2571fc3d-841c-4237-a770-99e33f78171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_train distribution:\\n\", y_train.value_counts())\n",
    "print(\"y_test distribution:\\n\", y_test.value_counts())\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "26a7d33f-1f37-4859-8452-cf7254e64952",
   "metadata": {},
   "source": [
    "Perfect.\n",
    "\n",
    "Train/test split is correct:\n",
    "Train: 6,376 samples\n",
    "Test: 1,594 samples\n",
    "Class balance preserved (stratified split worked)\n",
    "\n",
    "This is clean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63158bb1-990b-4471-acd7-6f2d7f44b3a5",
   "metadata": {},
   "source": [
    "### Train XGBoost Classifier# Train XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd41b4c1-5a02-4b68-b143-a0b8065d890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(\n",
    "    objective=\"multi:softprob\",\n",
    "    num_class=3,\n",
    "    n_estimators=300,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    eval_metric=\"mlogloss\"\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model training completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9404152a-7c71-4d6c-8df1-f862fcecd28f",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbb1e49-4cde-4f6d-8766-45210159dbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ROC-AUC (multi-class)\n",
    "y_test_bin = label_binarize(y_test, classes=[0, 1, 2])\n",
    "y_pred_prob = model.predict_proba(X_test)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test_bin, y_pred_prob, multi_class=\"ovr\")\n",
    "print(\"\\nROC-AUC:\", roc_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99386545-d4f8-435e-b2b3-33dee3898746",
   "metadata": {},
   "source": [
    "### Check Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0689a9-c0da-487d-9be3-276ba4ac2131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "\n",
    "# Test accuracy again\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73ed5de-c5e0-4e2a-96bc-96c2950b7d37",
   "metadata": {},
   "source": [
    "### Let's Check More Properly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512ff6a5-93e0-47c3-a4aa-b48ce539d678",
   "metadata": {},
   "source": [
    "Accuracy alone is not enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70f49b5-b9f9-42f4-adef-8413edfd1757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Train Classification Report:\\n\")\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "\n",
    "print(\"\\nTest Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c68e0de-459c-448a-a230-b126eb637a90",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f4d008-fc89-49e6-bfd9-878f0d736ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[0,1,2],\n",
    "            yticklabels=[0,1,2])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d353182-c568-45aa-b63e-0fa09c347ac7",
   "metadata": {},
   "source": [
    "### Crosstab (Actual vs Predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6046ce6-b59e-47bd-94e2-c38bec3c7e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "crosstab = pd.crosstab(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    rownames=[\"Actual\"],\n",
    "    colnames=[\"Predicted\"]\n",
    ")\n",
    "\n",
    "print(crosstab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e3634d-842a-4be9-86c9-9f9817bfffc9",
   "metadata": {},
   "source": [
    "### Crosstab with Percentages (Even Better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ed4cf7-c4d3-4ee7-b145-9b6e5fbad948",
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab_percent = pd.crosstab(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    normalize=\"index\"\n",
    ")\n",
    "\n",
    "print(crosstab_percent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b287b1fd-81d4-452b-a886-e103c3f7c845",
   "metadata": {},
   "source": [
    "### Cross-Validation (More Serious Overfitting Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583524f1-c59b-45e6-8aa0-fe1071c8dc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "cv_scores = cross_val_score(\n",
    "    model,\n",
    "    X,\n",
    "    y,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", np.mean(cv_scores))\n",
    "print(\"Std CV accuracy:\", np.std(cv_scores))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a9e0f0c3-0279-416e-b339-bf3dfb3fe6ba",
   "metadata": {},
   "source": [
    "2Ô∏è‚É£ CV Mean vs Test Accuracy\n",
    "CV mean ‚âà 95.1%\n",
    "Test accuracy ‚âà 96.3%\n",
    "Very close.\n",
    "\n",
    "That confirms:\n",
    "‚úî No severe overfitting\n",
    "‚úî Model generalizes consistently\n",
    "\n",
    "3Ô∏è‚É£ Why CV < Test Slightly?\n",
    "Normal variation due to:\n",
    "Different fold splits\n",
    "Test set slightly easier\n",
    "Random sampling differences\n",
    "Nothing concerning.\n",
    "\n",
    "üéØ Professional Conclusion\n",
    "\n",
    "Model status:\n",
    "\n",
    "‚úî Robust\n",
    "‚úî Stable\n",
    "‚úî Generalizable\n",
    "‚úî No data leakage beyond constructed label logic\n",
    "‚úî Balanced class behavior\n",
    "\n",
    "From a modeling perspective, this is clean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e55fe6-3655-486b-a71f-5ae660adb2b0",
   "metadata": {},
   "source": [
    "## model explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f892c39b-8327-443f-aa8a-0951f016b3b4",
   "metadata": {},
   "source": [
    "### XGBoost Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599ce003-c214-4e94-81a3-3a96ea3ed98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Get feature importance scores\n",
    "importance = model.feature_importances_\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": model_features,\n",
    "    \"Importance\": importance\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "print(importance_df)\n",
    "\n",
    "# Plot\n",
    "plt.figure()\n",
    "plt.barh(importance_df[\"Feature\"], importance_df[\"Importance\"])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Feature Importance (XGBoost)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6c209666-595c-4f70-98ce-5f7bcf36de4c",
   "metadata": {},
   "source": [
    "üîé Does This Make Financial Sense?\n",
    "Yes. Completely.\n",
    "\n",
    "üîπ Liquidity dominates\n",
    "current_ratio\n",
    "cash_ratio\n",
    "Liquidity is the strongest predictor of short-term financial stress.\n",
    "That aligns with real banking models.\n",
    "\n",
    "üîπ Leverage is second strongest\n",
    "debt_to_equity\n",
    "debt_to_assets\n",
    "Highly leveraged firms are more vulnerable.\n",
    "Again, financially logical.\n",
    "\n",
    "üîπ Profitability matters but less\n",
    "ROE\n",
    "ROA\n",
    "Net margin\n",
    "\n",
    "Profitability impacts long-term sustainability, but liquidity crisis happens faster.\n",
    "Model captured this nuance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6338860-1b70-41db-a4c5-bb7cc76a2a6b",
   "metadata": {},
   "source": [
    "## SHAP explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0594aa0e-d178-4411-a778-8d09d10715ef",
   "metadata": {},
   "source": [
    "this is what makes your project enterprise-grade."
   ]
  },
  {
   "cell_type": "raw",
   "id": "642bd90f-1f3e-4f9c-bca9-d85ca6332c8d",
   "metadata": {},
   "source": [
    "üîç What Is SHAP?\n",
    "\n",
    "SHAP = SHapley Additive exPlanations\n",
    "    It is a method to explain:\n",
    "    Why did the model make this prediction?\n",
    "\n",
    "It tells you:\n",
    "Which features pushed the prediction higher\n",
    "Which features pushed it lower\n",
    "By how much\n",
    "\n",
    "üß† Why SHAP Exists\n",
    "Machine learning models (especially XGBoost) are:\n",
    "Powerful\n",
    "Nonlinear\n",
    "Hard to interpret\n",
    "\n",
    "Accuracy alone is not enough in finance.\n",
    "Banks require:\n",
    "Explainability\n",
    "Auditability\n",
    "Transparency\n",
    "SHAP provides that.\n",
    "\n",
    "üéØ Core Idea (Simple Version)\n",
    "For one company:\n",
    "\n",
    "The model predicts:\n",
    "üëâ Risk Category = High\n",
    "\n",
    "SHAP explains:\n",
    "debt_to_equity ‚Üí increased risk by +0.8\n",
    "current_ratio ‚Üí decreased risk by -0.4\n",
    "ROA ‚Üí increased risk by +0.3\n",
    "free_cash_flow ‚Üí decreased risk by -0.2\n",
    "\n",
    "Final decision = sum of all contributions.\n",
    "It breaks prediction into feature contributions.\n",
    "\n",
    "üìä Two Types of SHAP Explanations\n",
    "1Ô∏è‚É£ Global Explanation\n",
    "Which features are most important overall?\n",
    "(Like advanced feature importance)\n",
    "\n",
    "2Ô∏è‚É£ Local Explanation\n",
    "Why was THIS company classified as high risk?\n",
    "This is powerful for:\n",
    "    Credit committees\n",
    "    Regulatory reporting\n",
    "    Stakeholder presentations\n",
    "\n",
    "üî• Why SHAP Is Perfect For Your Project\n",
    "Your project includes:\n",
    "    Financial ratios\n",
    "    Risk classification\n",
    "    Business users\n",
    "With SHAP, you can say:\n",
    "    ‚ÄúClient classified as High Risk primarily due to elevated leverage and negative profitability metrics.‚Äù\n",
    "That‚Äôs enterprise-level storytelling.\n",
    "\n",
    "üè¶ In Real Banking Systems\n",
    "SHAP is used for:\n",
    "    Credit scoring\n",
    "    Loan approval models\n",
    "    Fraud detection\n",
    "    Regulatory compliance (Basel, IFRS 9)\n",
    "So adding SHAP makes your project realistic.\n",
    "\n",
    "üéì Interview Value\n",
    "If interviewer asks:\n",
    "‚ÄúHow do you explain your model?‚Äù\n",
    "\n",
    "You say:\n",
    "‚ÄúI used SHAP to generate both global and per-client risk explanations to ensure transparency and business interpretability.‚Äù\n",
    "\n",
    "That‚Äôs strong."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c576d8-390a-46b9-9a27-0d4048e22eb3",
   "metadata": {},
   "source": [
    "### Create Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dbf4c7-3988-40a6-b469-a9fd67eff0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "print(\"SHAP imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12051ec7-5e57-4276-8066-4004e11e1dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Create TreeExplainer for XGBoost model\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# Compute SHAP values for test set\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "print(\"SHAP values computed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d81a1b-39b4-493c-9661-f1a345825198",
   "metadata": {},
   "source": [
    "### Global Summary Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7d2507-2543-459e-9bf7-b5bdcc574ada",
   "metadata": {},
   "source": [
    "This shows which features contribute most to predictions overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20d5b77-da91-47ea-bb0e-f8f04b0640bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b0ab2962-2fcc-4ad0-bfe7-f5cdae7e0ec2",
   "metadata": {},
   "source": [
    "üìä SHAP Summary Interpretation\n",
    "\n",
    "From the beeswarm:\n",
    "\n",
    "üîπ Top Features (by impact magnitude)\n",
    "\n",
    "1Ô∏è‚É£ debt_to_equity\n",
    "2Ô∏è‚É£ current_ratio\n",
    "3Ô∏è‚É£ debt_to_assets\n",
    "\n",
    "This aligns with:\n",
    "    XGBoost feature importance\n",
    "    Financial theory\n",
    "    Your composite risk logic\n",
    "That‚Äôs consistency across methods.\n",
    "\n",
    "üîé Directional Behavior (Very Important)\n",
    "\n",
    "In SHAP:\n",
    "\n",
    "Red dots = high feature values\n",
    "Blue dots = low feature values\n",
    "\n",
    "And:\n",
    "\n",
    "Right side ‚Üí increases risk prediction\n",
    "Left side ‚Üí decreases risk prediction\n",
    "\n",
    "üîπ debt_to_equity\n",
    "\n",
    "High values (red) push predictions toward High Risk.\n",
    "Low values (blue) push toward Low Risk.\n",
    "\n",
    "Financially correct.\n",
    "\n",
    "üîπ current_ratio\n",
    "\n",
    "High liquidity (red) pushes toward Low Risk.\n",
    "Low liquidity (blue) pushes toward High Risk.\n",
    "\n",
    "Again, financially logical.\n",
    "\n",
    "üîπ debt_to_assets\n",
    "\n",
    "High leverage ‚Üí pushes right (higher risk).\n",
    "Correct behavior.\n",
    "\n",
    "üéØ Important Conclusion\n",
    "\n",
    "Your model is:\n",
    "\n",
    "‚úî Learning economically meaningful relationships\n",
    "‚úî Interpretable\n",
    "‚úî Consistent with financial intuition\n",
    "‚úî Not behaving randomly\n",
    "\n",
    "This is enterprise-level modeling."
   ]
  },
  {
   "cell_type": "raw",
   "id": "48631f2e-1156-453f-9502-085b60ee405c",
   "metadata": {},
   "source": [
    "Good. Now we move to local explainability.\n",
    "\n",
    "We will:\n",
    "\n",
    "1Ô∏è‚É£ Pick one company from the test set\n",
    "2Ô∏è‚É£ See its predicted risk category\n",
    "3Ô∏è‚É£ Break down feature contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9347e01c-50f8-4703-8554-26ea379bc636",
   "metadata": {},
   "source": [
    "### Select One Test Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a34be66-0c80-4ca8-803c-d8180b88d010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick first test sample\n",
    "sample_index = X_test.index[0]\n",
    "\n",
    "sample_data = X_test.loc[[sample_index]]\n",
    "\n",
    "print(\"Actual Risk:\", y_test.loc[sample_index])\n",
    "print(\"Predicted Risk:\", model.predict(sample_data)[0])\n",
    "\n",
    "sample_data\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cb87c0d8-3931-4868-91a6-2a3f05704c2e",
   "metadata": {},
   "source": [
    "Good. This is a clean example.\n",
    "\n",
    "Company:\n",
    "Actual Risk = 1 (Medium)\n",
    "Predicted Risk = 1 (Medium)\n",
    "Prediction correct.\n",
    "\n",
    "Now we explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e11e7d9-930c-410f-b286-af12807b8515",
   "metadata": {},
   "source": [
    "### SHAP Explanation for This Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19985c1c-9b99-479e-b352-722d1c4d3325",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(shap_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2cd430-4d02-436d-b3d8-96ae872a79cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.array(shap_values).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268e41c1-783d-42b2-aa5a-f52e138f3795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find sample position in test set\n",
    "sample_position = list(X_test.index).index(sample_index)\n",
    "\n",
    "# Extract SHAP values for class 1\n",
    "shap_values_class1 = shap_values[sample_position, :, 1]\n",
    "\n",
    "shap.force_plot(\n",
    "    explainer.expected_value[1],  # expected value for class 1\n",
    "    shap_values_class1,\n",
    "    sample_data,\n",
    "    matplotlib=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "837459cb-506d-4dc9-b094-1ba06c75b9ee",
   "metadata": {},
   "source": [
    "Excellent. Now this is real explainability.\n",
    "\n",
    "Let‚Äôs interpret it properly.\n",
    "\n",
    "üìä SHAP Force Plot Interpretation\n",
    "\n",
    "Top right shows:\n",
    "f(x) = 1.80\n",
    "That is the model‚Äôs internal score for class 1 (Medium Risk).\n",
    "The base value is the average log-odds for that class.\n",
    "Now look at feature pushes.\n",
    "\n",
    "üî¥ Features Pushing Risk Up (Red ‚Üí Increase Risk Toward Class 1)\n",
    "\n",
    "From left to right:\n",
    "    debt_to_assets = 0.70\n",
    "    free_cash_flow = -69M\n",
    "    cash_ratio = 0.29\n",
    "    debt_to_equity = 1.21\n",
    "    current_ratio = 0.82\n",
    "\n",
    "These collectively push the company toward Medium Risk.\n",
    "\n",
    "Why?\n",
    "    Moderate leverage\n",
    "    Negative free cash flow\n",
    "    Not very strong liquidity\n",
    "Financially consistent.\n",
    "\n",
    "üîµ Feature Pushing Risk Down (Blue ‚Üí Lower Risk)\n",
    "    return_on_equity = -1.04\n",
    "Interestingly, negative ROE slightly pulls prediction away from class 1.\n",
    "This happens because extremely poor profitability may push toward High Risk instead of Medium.\n",
    "That‚Äôs a nonlinear effect ‚Äî and it‚Äôs correct behavior.\n",
    "\n",
    "üß† Business-Level Explanation\n",
    "If you were presenting this to a credit committee:\n",
    "‚ÄúThis company is classified as Medium Risk primarily due to moderate leverage levels and negative free cash flow, indicating pressure on liquidity. Although profitability metrics are weak, they do not yet place the firm into the high-risk category.‚Äù\n",
    "That‚Äôs enterprise-grade explanation.\n",
    "\n",
    "üéØ What You Just Achieved\n",
    "You now have:\n",
    "    Global model explainability\n",
    "    Local per-company explainability\n",
    "    Financially logical behavior\n",
    "    Audit-ready decision breakdown\n",
    "\n",
    "This is beyond typical student projects."
   ]
  },
  {
   "cell_type": "raw",
   "id": "58d15622-f809-44c2-8d3b-84d41f61e497",
   "metadata": {},
   "source": [
    "Now we build the ML + LLM integration layer.\n",
    "\n",
    "This is what turns your project into:\n",
    "\n",
    "Automated Financial Risk Scoring Platform (Machine Learning + LLM)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "feb1f4a6-a365-4738-a9c6-f1c7bcaf6879",
   "metadata": {},
   "source": [
    "üéØ Goal\n",
    "\n",
    "Take:\n",
    "    Financial ratios\n",
    "    SHAP feature contributions\n",
    "    Predicted risk class\n",
    "\n",
    "And generate:\n",
    "A clean, human-readable business risk explanation."
   ]
  },
  {
   "cell_type": "raw",
   "id": "2cf40740-5911-474d-8313-09de01df09ae",
   "metadata": {},
   "source": [
    "üß† Architecture\n",
    "\n",
    "Pipeline:\n",
    "Financial Data ‚Üí XGBoost ‚Üí SHAP ‚Üí Structured Explanation Prompt ‚Üí LLM ‚Üí Business Sum\n",
    "\n",
    "We‚Äôll build:\n",
    "1Ô∏è‚É£ A function to extract top SHAP drivers\n",
    "2Ô∏è‚É£ A structured prompt\n",
    "3Ô∏è‚É£ Call OpenAI API\n",
    "4Ô∏è‚É£ Generate explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f0f013-141f-4228-adda-97cb906ceb00",
   "metadata": {},
   "source": [
    "### Extract Top Contributing Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96880471-0225-49ca-96cf-c2a5cef43136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_top_shap_features(sample_position, class_index=1, top_n=3):\n",
    "    shap_vals = shap_values[sample_position, :, class_index]\n",
    "    feature_names = X_test.columns\n",
    "    \n",
    "    shap_df = pd.DataFrame({\n",
    "        \"feature\": feature_names,\n",
    "        \"shap_value\": shap_vals,\n",
    "        \"feature_value\": X_test.iloc[sample_position].values\n",
    "    })\n",
    "    \n",
    "    shap_df[\"abs_shap\"] = np.abs(shap_df[\"shap_value\"])\n",
    "    shap_df = shap_df.sort_values(\"abs_shap\", ascending=False)\n",
    "    \n",
    "    return shap_df.head(top_n)\n",
    "\n",
    "top_features = get_top_shap_features(sample_position, class_index=1)\n",
    "top_features\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "56ffc997-873b-4fca-a1df-ca3bf6e5f66c",
   "metadata": {},
   "source": [
    "üß† What This Means Financially\n",
    "\n",
    "Current ratio (0.82) ‚Üí below 1 ‚Üí weak short-term liquidity ‚Üí increases risk\n",
    "Debt-to-equity (1.22) ‚Üí moderate leverage ‚Üí increases risk\n",
    "Cash ratio (0.30) ‚Üí low cash buffer ‚Üí increases risk\n",
    "\n",
    "All three signals point toward liquidity stress and leverage pressure.r\n",
    "The model is behaving logically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72fc821-149a-439d-b395-10110072b3b3",
   "metadata": {},
   "source": [
    "Now we convert this into an LLM-generated explanation.m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c34aac-9830-4f63-971f-0b25f75346b3",
   "metadata": {},
   "source": [
    "### Build Structured Prompt for LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e31d670-3f49-484e-a22e-265ab2b64458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_risk_prompt(predicted_class, top_features):\n",
    "    \n",
    "    risk_label_map = {\n",
    "        0: \"Low Risk\",\n",
    "        1: \"Medium Risk\",\n",
    "        2: \"High Risk\"\n",
    "    }\n",
    "    \n",
    "    explanation_points = \"\"\n",
    "    \n",
    "    for _, row in top_features.iterrows():\n",
    "        explanation_points += (\n",
    "            f\"- {row['feature']} = {row['feature_value']:.2f} \"\n",
    "            f\"(impact: {row['shap_value']:.3f})\\n\"\n",
    "        )\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "You are a financial risk analyst.\n",
    "\n",
    "The model has classified this company as: {risk_label_map[predicted_class]}.\n",
    "\n",
    "Key contributing financial indicators:\n",
    "\n",
    "{explanation_points}\n",
    "\n",
    "Generate a professional business-level explanation describing:\n",
    "- Why the company falls into this risk category\n",
    "- What financial weaknesses or strengths are driving this decision\n",
    "- Keep it concise and suitable for credit committee review.\n",
    "\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "predicted_class = model.predict(sample_data)[0]\n",
    "prompt_text = build_risk_prompt(predicted_class, top_features)\n",
    "\n",
    "print(prompt_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b508e24c-bbe0-4be5-94db-85fd6d546bd5",
   "metadata": {},
   "source": [
    "### Call OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5175dfd3-4768-40a5-b0de-83bd5f20cbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#code the above and not the below. and use your apikey\n",
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dc98c4-8c03-437b-953a-736dfaab96ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert financial risk analyst.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt_text}\n",
    "    ],\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "llm_explanation = response.choices[0].message.content\n",
    "\n",
    "print(llm_explanation)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a9830c22-f5db-4936-b054-b243cc61ac6a",
   "metadata": {},
   "source": [
    "This is excellent.\n",
    "\n",
    "You have successfully built:\n",
    "\n",
    "ML Model ‚Üí SHAP ‚Üí Structured Financial Drivers ‚Üí LLM ‚Üí Business-Grade Risk Narrative.\n",
    "\n",
    "That‚Äôs a real end-to-end AI system."
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ba9da67-b0c9-455a-812f-d6031bd4c11f",
   "metadata": {},
   "source": [
    "üîé What‚Äôs Good About This Output\n",
    "\n",
    "‚úî Clearly structured\n",
    "‚úî Explains each metric\n",
    "‚úî Connects metrics to risk\n",
    "‚úî Suitable for stakeholders"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d758781-3324-4e68-8ec0-aa06541e7139",
   "metadata": {},
   "source": [
    "üß† Now You Officially Have\n",
    "\n",
    "‚úî Financial data ingestion (SEC real data)\n",
    "‚úî Feature engineering with financial logic\n",
    "‚úî Risk score construction\n",
    "‚úî XGBoost classification\n",
    "‚úî Cross-validation\n",
    "‚úî SHAP global explainability\n",
    "‚úî SHAP local explanation\n",
    "‚úî LLM automated narrative generation\n",
    "\n",
    "This is a serious portfolio project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fa07a6-afa0-4f83-b317-ac20a99ae2f1",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625f7e44-e01d-46bc-925c-4630e7023f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\n",
    "r\"D:\\Resume\\KPMG\\Automated Financial Risk Scoring Platform (Machine Learning + LLM)\\financial-risk-platform\\models\\xgboost_risk_model.json\"\n",
    ")\n",
    "\n",
    "print(\"Model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68c4ba2-07d1-4797-93f3-0d21b445cfac",
   "metadata": {},
   "source": [
    "## interview questions and answersm"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b3ccd59d-150f-471c-a89b-9cc330a65829",
   "metadata": {},
   "source": [
    "Interviewer thinking:\n",
    "\n",
    "Is this a Kaggle toy project?\n",
    "\n",
    "Strong Answer:\n",
    "\n",
    "I used real SEC Financial Statement Data Sets from the U.S. Securities and Exchange Commission. The dataset includes structured balance sheet, income statement, and cash flow disclosures. I processed over 2 million financial records and engineered company-level financial ratios for modeling.\n",
    "\n",
    "Why this works:\n",
    "Real data\n",
    "Large scale\n",
    "Structured ingestion\n",
    "Not Kaggle"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f123b7e1-c31e-47c1-a8d9-13e127125d5a",
   "metadata": {},
   "source": [
    "üî• 2Ô∏è‚É£ ‚ÄúHow did you define risk labels?‚Äù\n",
    "\n",
    "This is the most important question.\n",
    "\n",
    "Interviewer thinking:\n",
    "\n",
    "Did you use real defaults or just fabricate labels?\n",
    "\n",
    "Correct Honest Answer:\n",
    "\n",
    "Since actual default events were not available, I constructed a composite financial stress score using liquidity, leverage, and profitability ratios. I then segmented companies into Low, Medium, and High risk categories based on percentile thresholds. The model was trained to learn nonlinear relationships across these financial drivers.\n",
    "\n",
    "Why this works:\n",
    "You admit synthetic labeling\n",
    "You show financial reasoning\n",
    "You explain methodology clearly\n",
    "No exaggeration\n",
    "\n",
    "Never claim:\n",
    "‚ÄúThe model predicts actual bankruptcy.‚Äù\n",
    "That would be wrong."
   ]
  },
  {
   "cell_type": "raw",
   "id": "ad9f49d2-690a-43c5-ae44-5dda6bab84da",
   "metadata": {},
   "source": [
    "üî• 3Ô∏è‚É£ ‚ÄúWhy is your accuracy so high?‚Äù\n",
    "\n",
    "They WILL ask this.\n",
    "\n",
    "Strong Answer:\n",
    "\n",
    "The risk labels were constructed directly from financial ratios. Therefore, the model is effectively learning nonlinear interactions across the same variables used in score construction. The high performance reflects consistency between the scoring logic and the classification model rather than predictive default modeling.\n",
    "\n",
    "This shows:\n",
    "You understand label construction\n",
    "You understand why 96% is high\n",
    "You understand leakage risks\n",
    "\n",
    "This answer impresses senior interviewers."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d13b315a-e006-4cec-99e9-a6a3c5df789e",
   "metadata": {},
   "source": [
    "üî• 4Ô∏è‚É£ ‚ÄúHow did you handle financial outliers?‚Äù\n",
    "\n",
    "Very important.\n",
    "\n",
    "Strong Answer:\n",
    "\n",
    "Financial ratios like debt-to-equity and current ratio can explode due to near-zero denominators. I applied log transformations and percentile capping to stabilize heavy-tailed distributions while preserving economic meaning. This improved model robustness and interpretability.\n",
    "\n",
    "This shows:\n",
    "Domain awareness\n",
    "Statistical maturity\n",
    "Practical experience"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf439202-b504-4df8-b708-2e972b523d3f",
   "metadata": {},
   "source": [
    "üî• 5Ô∏è‚É£ ‚ÄúHow did you check for overfitting?‚Äù\n",
    "\n",
    "You can say:\n",
    "\n",
    "I evaluated train vs test performance, performed 5-fold cross-validation, and analyzed confusion matrices. The model showed stable cross-validation accuracy (~95%) with low variance and minimal train-test gap, indicating good generalization.\n",
    "\n",
    "Concise. Strong."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0defc367-35c4-4753-a18b-b81ddf193db1",
   "metadata": {},
   "source": [
    "üî• 6Ô∏è‚É£ ‚ÄúHow is this different from just using the composite score?‚Äù\n",
    "\n",
    "This is a smart question.\n",
    "\n",
    "Answer:\n",
    "\n",
    "The composite score is linear and manually weighted. XGBoost captures nonlinear interactions between liquidity, leverage, and profitability metrics, potentially improving discrimination across borderline cases. The ML model also enables feature importance analysis and SHAP-based explanations.\n",
    "\n",
    "That shows:\n",
    "You understand linear vs nonlinear\n",
    "You justify ML usage"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e894d867-68dc-4417-8a83-f9335fe45cdd",
   "metadata": {},
   "source": [
    "üî• 7Ô∏è‚É£ ‚ÄúWhy did you use SHAP?‚Äù\n",
    "\n",
    "Answer:\n",
    "\n",
    "In financial risk modeling, explainability is critical for regulatory compliance and stakeholder trust. SHAP provides both global and per-company feature contributions, enabling transparent decision support suitable for credit committees.\n",
    "\n",
    "This is enterprise-level thinking."
   ]
  },
  {
   "cell_type": "raw",
   "id": "08ad31a2-e546-47b1-95af-3d1432ed0110",
   "metadata": {},
   "source": [
    "üî• 8Ô∏è‚É£ ‚ÄúWhere does the LLM fit in?‚Äù\n",
    "\n",
    "Answer:\n",
    "\n",
    "The LLM layer converts quantitative SHAP outputs into business-readable narratives. It does not influence model predictions; it enhances interpretability for non-technical stakeholders by translating financial drivers into structured risk summaries.\n",
    "\n",
    "Important:\n",
    "You clarify separation between ML and LLM."
   ]
  },
  {
   "cell_type": "raw",
   "id": "9104ffaf-4127-42ed-a8ba-994a5361da5d",
   "metadata": {},
   "source": [
    "üî• 9Ô∏è‚É£ ‚ÄúWhat would you improve if given real default data?‚Äù\n",
    "\n",
    "Answer:\n",
    "\n",
    "I would replace synthetic risk labels with actual historical default or rating downgrade events and shift toward probability-of-default modeling. Additionally, I would incorporate time-series features and macroeconomic variables to improve predictive realism.\n",
    "\n",
    "This shows forward-thinking maturity."
   ]
  },
  {
   "cell_type": "raw",
   "id": "54f4a54e-62d7-46c2-87cb-84d98e032a60",
   "metadata": {},
   "source": [
    "üî• 10Ô∏è‚É£ ‚ÄúIs this production-ready?‚Äù\n",
    "\n",
    "Strong answer:\n",
    "\n",
    "The modeling pipeline is production-structured, including saved models, modular architecture, and explainability layers. However, production deployment would require model monitoring, drift detection, and regulatory validation before use in a live credit environment.\n",
    "\n",
    "That‚Äôs senior-level thinking."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a1708455-e5ed-463a-9fe7-b5dc48bf7054",
   "metadata": {},
   "source": [
    "Why not just use logistic regression instead of XGBoost?\n",
    "\n",
    "Logistic regression could have been used, especially as a baseline model. However, logistic regression assumes linear relationships between features and the log-odds of the target. In financial risk modeling, interactions between leverage, liquidity, and profitability are often nonlinear. XGBoost can capture these nonlinear relationships and feature interactions more effectively. Additionally, tree-based models are less sensitive to feature scaling and can handle skewed financial distributions more naturally."
   ]
  },
  {
   "cell_type": "raw",
   "id": "99db7441-913e-464c-9403-37a18c779619",
   "metadata": {},
   "source": [
    "üéØ The Most Important Rule\n",
    "\n",
    "Never oversell.\n",
    "\n",
    "Be confident but technically accurate.\n",
    "\n",
    "If you say:\n",
    "\n",
    "‚ÄúThis predicts bankruptcy.‚Äù\n",
    "\n",
    "You lose credibility.\n",
    "\n",
    "If you say:\n",
    "\n",
    "‚ÄúThis simulates a financial stress scoring framework using real financial disclosures.‚Äù\n",
    "\n",
    "You win credibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50f2a3e-c66a-48d8-aa6f-0244a9da50ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
